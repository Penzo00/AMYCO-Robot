{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Percorso al file di log di TensorBoard\n",
    "log_file = 'logs/train/events.out.tfevents.1731834125.DESKTOP-D4HA6VL.3990033.2.v2'\n",
    "\n",
    "# Inizializza le liste per memorizzare i valori di accuracy e loss\n",
    "epochs = []\n",
    "accuracy = []\n",
    "loss = []\n",
    "\n",
    "# Itera sugli eventi nel file di log\n",
    "for event in tf.compat.v1.train.summary_iterator(log_file):\n",
    "    for value in event.summary.value:\n",
    "        if value.tag == 'epoch_accuracy':\n",
    "            epochs.append(event.step)\n",
    "            accuracy.append(value.simple_value)\n",
    "        elif value.tag == 'epoch_loss':\n",
    "            loss.append(value.simple_value)\n",
    "\n",
    "# Crea i grafici per accuracy e loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, accuracy, label='Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, label='Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%load_ext tensorboard\n",
   "id": "4924f27d7c5a7443",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%tensorboard --logdir logs",
   "id": "7e3bf439359a328e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%tensorboard --logdir logs_FT",
   "id": "7e3610068e352443",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Impostazioni per migliorare l'estetica dei grafici\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "plt.rcParams[\"axes.titlesize\"] = 16\n",
    "plt.rcParams[\"axes.labelsize\"] = 14\n",
    "\n",
    "# Funzione per creare un singolo grafico\n",
    "def plot_metric(data, title, xlabel, ylabel, labels, save_as=None):\n",
    "    plt.figure()\n",
    "    for df, label in zip(data, labels):\n",
    "        sns.lineplot(data=df, x=\"Step\", y=\"Value\", label=label, linewidth=2.5)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend(title=\"Dataset\")\n",
    "    plt.tight_layout()\n",
    "    if save_as:\n",
    "        plt.savefig(save_as, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Funzione per adattare le epoche del fine-tuning\n",
    "def adjust_fine_tuning_epochs(dataframes, max_standard_epoch=24):\n",
    "    adjusted_dataframes = []\n",
    "    for df in dataframes:\n",
    "        df_adjusted = df.copy()\n",
    "        df_adjusted[\"Step\"] += max_standard_epoch  # Aggiusta le epoche\n",
    "        adjusted_dataframes.append(df_adjusted)\n",
    "    return adjusted_dataframes\n",
    "\n",
    "# Caricamento dei file CSV (aggiungere i tuoi file qui)\n",
    "csv_files = {\n",
    "    \"accuracy\": [\n",
    "        (\"train.csv\", \"Training Accuracy\"),\n",
    "        (\"validation.csv\", \"Validation Accuracy\"),\n",
    "        (\"train1.csv\", \"Fine-tuned Training Accuracy\"),\n",
    "        (\"validation1.csv\", \"Fine-tuned Validation Accuracy\"),\n",
    "    ],\n",
    "    \"top5_accuracy\": [\n",
    "        (\"top.csv\", \"Training Top-5 Accuracy\"),\n",
    "        (\"topv.csv\", \"Validation Top-5 Accuracy\"),\n",
    "        (\"topft.csv\", \"Fine-tuned Training Top-5 Accuracy\"),\n",
    "        (\"topvft.csv\", \"Fine-tuned Validation Top-5 Accuracy\"),\n",
    "    ],\n",
    "    \"learning_rate\": [\n",
    "        (\"lr.csv\", \"Learning Rate\"),\n",
    "        (\"lrft.csv\", \"Fine-tuned Learning Rate\"),\n",
    "    ],\n",
    "    \"loss\": [\n",
    "        (\"loss.csv\", \"Training Loss\"),\n",
    "        (\"lossv.csv\", \"Validation Loss\"),\n",
    "        (\"lossft.csv\", \"Fine-tuned Training Loss\"),\n",
    "        (\"lossvft.csv\", \"Fine-tuned Validation Loss\"),\n",
    "    ],\n",
    "    \"eval_accuracy\": [\n",
    "        (\"evalit.csv\", \"Validation Accuracy\"),\n",
    "        (\"evalift.csv\", \"Fine-tuned Validation Accuracy\"),\n",
    "    ],\n",
    "    \"eval_loss\": [\n",
    "        (\"eval_loss_vs_iter.csv\", \"Validation Loss\"),\n",
    "        (\"fine_tuned_eval_loss_vs_iter.csv\", \"Fine-tuned Validation Loss\"),\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Funzione per adattare le iterazioni del fine-tuning\n",
    "def adjust_fine_tuning_iterations(dataframes, max_standard_iteration):\n",
    "    adjusted_dataframes = []\n",
    "    for df in dataframes:\n",
    "        df_adjusted = df.copy()\n",
    "        df_adjusted[\"Step\"] += max_standard_iteration  # Aggiusta le iterazioni\n",
    "        adjusted_dataframes.append(df_adjusted)\n",
    "    return adjusted_dataframes\n",
    "\n",
    "# Loop per creare i grafici\n",
    "for metric, files in csv_files.items():\n",
    "    data = []\n",
    "    labels = []\n",
    "    fine_tuning_data = []\n",
    "    fine_tuning_labels = []\n",
    "    \n",
    "    for file, label in files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            if \"Fine-tuned\" in label:\n",
    "                fine_tuning_data.append(df)  # Salva dati fine-tuning\n",
    "                fine_tuning_labels.append(label)\n",
    "            else:\n",
    "                data.append(df)  # Salva dati standard\n",
    "                labels.append(label)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {file} non trovato. Saltato.\")\n",
    "    \n",
    "    # Adattamento delle epoche o iterazioni per il fine-tuning\n",
    "    if fine_tuning_data:\n",
    "        if metric in [\"eval_accuracy\", \"eval_loss\"]:\n",
    "            # Adatta le iterazioni per i grafici vs Iteration\n",
    "            max_standard_iteration = max(df[\"Step\"].max() for df in data) if data else 0\n",
    "            fine_tuning_data = adjust_fine_tuning_iterations(fine_tuning_data, max_standard_iteration)\n",
    "        else:\n",
    "            # Adatta le epoche per gli altri grafici\n",
    "            fine_tuning_data = adjust_fine_tuning_epochs(fine_tuning_data, max_standard_epoch=24)\n",
    "    \n",
    "    # Aggiungi i dati del fine-tuning ai dati principali\n",
    "    data.extend(fine_tuning_data)\n",
    "    labels.extend(fine_tuning_labels)\n",
    "    \n",
    "    # Titoli specifici per metrica\n",
    "    if metric == \"accuracy\":\n",
    "        title = \"Accuracy (Training, Validation, Fine-tuned)\"\n",
    "        ylabel = \"Accuracy\"\n",
    "    elif metric == \"top5_accuracy\":\n",
    "        title = \"Top-5 Accuracy (Training, Validation, Fine-tuned)\"\n",
    "        ylabel = \"Top-5 Accuracy\"\n",
    "    elif metric == \"learning_rate\":\n",
    "        title = \"Learning Rate During Training\"\n",
    "        ylabel = \"Learning Rate\"\n",
    "    elif metric == \"loss\":\n",
    "        title = \"Loss (Training, Validation, Fine-tuned)\"\n",
    "        ylabel = \"Loss\"\n",
    "    elif metric == \"eval_accuracy\":\n",
    "        title = \"Evaluation Accuracy vs Iteration (Including Fine-tuned)\"\n",
    "        ylabel = \"Accuracy\"\n",
    "    elif metric == \"eval_loss\":\n",
    "        title = \"Evaluation Loss vs Iteration (Including Fine-tuned)\"\n",
    "        ylabel = \"Loss\"\n",
    "    else:\n",
    "        title = metric.capitalize()\n",
    "        ylabel = metric.capitalize()\n",
    "    \n",
    "    # Disegna il grafico se ci sono dati validi\n",
    "    if data:\n",
    "        xlabel = \"Epoch\" if metric not in [\"eval_accuracy\", \"eval_loss\"] else \"Iteration\"\n",
    "        plot_metric(data, title, xlabel, ylabel, labels, save_as=f\"{metric}.png\")\n"
   ],
   "id": "ad8b8417247117e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load CSV files for Learning Rate\n",
    "data_lr_train = pd.read_csv(\"train.csv\")\n",
    "data_lr_finetune_train = pd.read_csv(\"train1.csv\")\n",
    "plot_combined(data_train, data_val, data_finetune_train, data_finetune_val, parameter, ylabel, title)"
   ],
   "id": "80f44b6b3442ae0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load CSV files for Learning Rate\n",
    "data_lr_train = pd.read_csv(\"learning_rate_training.csv\")\n",
    "data_lr_finetune_train = pd.read_csv(\"learning_rate_finetune_training.csv\")\n",
    "\n",
    "# Plot Learning Rate\n",
    "plot_learning_rate(data_lr_train, data_lr_finetune_train)"
   ],
   "id": "30d2b28384b6bd16",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
